<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"flat"},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="期末复习">
<meta name="keywords" content="Python,机器学习,数据挖掘">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘复习">
<meta property="og:url" content="https://Olvi73.github.io/p/4757.html">
<meta property="og:site_name" content="Olvi73&#39;s Blog">
<meta property="og:description" content="期末复习">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://gitee.com/Olvi73/img/raw/master/Box-plot.png">
<meta property="og:image" content="https://gitee.com/Olvi73/img/raw/master/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.jpg">
<meta property="og:image" content="https://gitee.com/Olvi73/img/raw/master/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%AD%A5%E9%AA%A4.jpg">
<meta property="og:updated_time" content="2021-06-16T02:29:22.452Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据挖掘复习">
<meta name="twitter:description" content="期末复习">
<meta name="twitter:image" content="https://gitee.com/Olvi73/img/raw/master/Box-plot.png">
  <link rel="canonical" href="https://Olvi73.github.io/p/4757">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>数据挖掘复习 | Olvi73's Blog</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b7431675845c02388491f33af09a5280";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>
    
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Olvi73's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-playlist">
      
    

    <a href="/playlist/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>歌单</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

    

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    

  <a href="https://github.com/Olvi73" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://Olvi73.github.io/p/4757.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Olvi73">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olvi73's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">数据挖掘复习

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2021-06-13 19:05:00" itemprop="dateCreated datePublished" datetime="2021-06-13T19:05:00+08:00">2021-06-13</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-16 10:29:22" itemprop="dateModified" datetime="2021-06-16T10:29:22+08:00">2021-06-16</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/数据挖掘/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/p/4757.html#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/p/4757.html" itemprop="commentCount"></span></a>
  </span>
  
  
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>9.1k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>8 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>期末复习</p>
<a id="more"></a>

<h1 id="数据挖掘"><a href="#数据挖掘" class="headerlink" title="数据挖掘"></a>数据挖掘</h1><h2 id="数据挖掘基本任务"><a href="#数据挖掘基本任务" class="headerlink" title="数据挖掘基本任务"></a>数据挖掘基本任务</h2><p>数据挖掘的基本任务包括利用分类与预测、聚类分析、关联规则、时序模式、偏差检测、智能推荐等方法，帮助企业提取数据中蕴含的商业价值，提高企业的竞争力。</p>
<h2 id="数据挖掘建模过程"><a href="#数据挖掘建模过程" class="headerlink" title="数据挖掘建模过程"></a>数据挖掘建模过程</h2><ol>
<li>定义挖掘目标</li>
<li>数据取样</li>
<li>数据探索</li>
<li>数据预处理</li>
<li>挖掘建模</li>
<li>模型评价</li>
</ol>
<h3 id="1-目标定义"><a href="#1-目标定义" class="headerlink" title="1.目标定义"></a>1.目标定义</h3><ol>
<li><p>任务理解</p>
</li>
<li><p>指标明确</p>
</li>
</ol>
<h3 id="2-数据采集"><a href="#2-数据采集" class="headerlink" title="2.数据采集"></a>2.数据采集</h3><ol>
<li>建模抽样</li>
<li>质量把控</li>
<li>实时采集</li>
</ol>
<h3 id="3-数据整理"><a href="#3-数据整理" class="headerlink" title="3.数据整理"></a>3.数据整理</h3><ol>
<li>数据探索</li>
<li>数据清洗</li>
<li>数据变换</li>
</ol>
<h3 id="4-构建模型"><a href="#4-构建模型" class="headerlink" title="4.构建模型"></a>4.构建模型</h3><ol>
<li>模式发现</li>
<li>构建模型</li>
<li>验证模型</li>
</ol>
<h3 id="5-模型评价"><a href="#5-模型评价" class="headerlink" title="5.模型评价"></a>5.模型评价</h3><ol>
<li>设定评价标准</li>
<li>多模型对比</li>
<li>模型优化</li>
</ol>
<h3 id="6-模型发布"><a href="#6-模型发布" class="headerlink" title="6.模型发布"></a>6.模型发布</h3><ol>
<li>模型部署</li>
<li>模型重构</li>
</ol>
<h2 id="第三章-数据探索-P39"><a href="#第三章-数据探索-P39" class="headerlink" title="第三章 数据探索 P39"></a>第三章 数据探索 P39</h2><p><strong>需要考虑的问题</strong></p>
<ol>
<li>样本数据集的数量和质量是否满足模型构建的要求？</li>
<li>有没有出现从未设想过的数据状态？</li>
<li>其中有没有明显的规律和趋势？</li>
<li>各因素之间有什么样的关联性？</li>
</ol>
<h3 id="1-数据质量分析"><a href="#1-数据质量分析" class="headerlink" title="1.数据质量分析"></a>1.数据质量分析</h3><h4 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h4><p>检查原始数据中是否存在脏数据，脏数据一般指不符合要求以及不能直接进行相应分析的数据，如缺失值、异常值、不一致值、重复数据及含有特殊符号的数据</p>
<h4 id="缺失值分析"><a href="#缺失值分析" class="headerlink" title="缺失值分析"></a>缺失值分析</h4><h5 id="产生的原因"><a href="#产生的原因" class="headerlink" title="产生的原因"></a>产生的原因</h5><ol>
<li>信息暂时无法获取，或者获取信息的代价太大</li>
<li>信息被遗漏，包括人为因素遗漏及数据采集设备故障导致的非人为因素遗漏</li>
<li>属性值不存在，如一个未婚者的配偶姓名，一个儿童的固定收入</li>
</ol>
<h5 id="缺失值的影响"><a href="#缺失值的影响" class="headerlink" title="缺失值的影响"></a>缺失值的影响</h5><ol>
<li>数据挖掘建模将丢失大量的有用信息</li>
<li>数据挖掘模型所变现出的不确定性更加显著，规律更难把握</li>
<li>包含空值的数据回事建模过程陷入混乱，导致不可靠的输出</li>
</ol>
<h5 id="缺失值的分析"><a href="#缺失值的分析" class="headerlink" title="缺失值的分析"></a>缺失值的分析</h5><ol>
<li>使用简单的统计分析，可以得到含有缺失值的属性的个数及每个属性的未缺失数、缺失数与缺失率等</li>
<li>对缺失值的处理<ul>
<li>删除存在缺失值的记录</li>
<li>对可能值进行插补</li>
<li>不处理</li>
</ul>
</li>
</ol>
<h4 id="异常值分析"><a href="#异常值分析" class="headerlink" title="异常值分析"></a>异常值分析</h4><p>异常值分析是检验数据是否有录入错误，是否含有不合常理的数据。</p>
<p>异常值是指样本中的个别值，其数值明显偏离其他的观测值。</p>
<p>异常值也称为<strong>离群点</strong>，异常值分析也称为<strong>离群点分析</strong></p>
<h5 id="1-简单统计量分析"><a href="#1-简单统计量分析" class="headerlink" title="1. 简单统计量分析"></a>1. 简单统计量分析</h5><p>对变量进行描述性统计，进而查看哪些数据是不合理的，如统计最大值和最小值，用来判断这个变量的取值是否超出了合理范围。</p>
<h5 id="2-3σ准则"><a href="#2-3σ准则" class="headerlink" title="2. 3σ准则"></a>2. 3σ准则</h5><blockquote>
<p>在 <a href="http://www.baike.com/sowiki/正态分布?prd=content_doc_search" target="_blank" rel="noopener">正态分布</a> 中σ代表 <a href="http://www.baike.com/sowiki/标准差?prd=content_doc_search" target="_blank" rel="noopener">标准差</a> ,μ代表 <a href="http://www.baike.com/sowiki/均值?prd=content_doc_search" target="_blank" rel="noopener">均值</a> 。x=μ即为图像的对称轴<br>3σ原则为<br>数值分布在（μ-σ,μ+σ)中的概率为0.6826<br>数值分布在（μ-2σ,μ+2σ)中的概率为0.9544<br>数值分布在（μ-3σ,μ+3σ)中的概率为0.9974<br>可以认为，Y 的取值几乎全部集中在（μ-3σ,μ+3σ)] <a href="http://www.baike.com/sowiki/区间?prd=content_doc_search" target="_blank" rel="noopener">区间</a>内，超出这个范围的可能性仅占不到0.3%.</p>
</blockquote>
<p>3σ准则是建立在正态分布的等精度重复测量基础上而造成奇异数据的干扰或噪声难以满足正态分布.如果一组测量数据中某个测量值的残余误差的绝对值 νi＞3σ,则该测量值为坏值,应剔除.通常把等于 ±3σ的误差作为极限误差,对于正态分布的随机误差,落在 ±3σ以外的概率只有 0.27%,它在有限次测量中发生的可能性很小,故存在3σ准则.3σ准则是最常用也是最简单的粗大误差判别准则,它一般应用于测量次数充分多( n ≥30)或当 n＞10做粗略判别时的情况.</p>
<h5 id="3-箱型图分析"><a href="#3-箱型图分析" class="headerlink" title="3. 箱型图分析"></a>3. 箱型图分析</h5><p>箱形图依据实际数据绘制，不需要事先假定数据服从特定的分布形式，没有对数据作任何限制性要求，它只是真实直观地表现数据分布的本来面貌；另一方面，箱形图判断异常值的标准以四分位数和四分位距为基础，四分位数具有一定的鲁棒性：多达25%的数据可以变得任意远而不会很大地扰动四分位数，所以异常值不能对这个标准施加影响，箱形图识别异常值的结果比较客观。由此可见，箱形图在识别异常值方面有一定的优越性。</p>
<ul>
<li><p>Q1，Q3</p>
</li>
<li><p>4分位间距(Interquartile Range) IQR=(Q3-Q1)/2</p>
</li>
<li><p>内限=Q1-1.5*IQR，Q3+1.5*IQR</p>
</li>
<li><p>外限=Q1-3*IQR，Q3+3*IQR</p>
</li>
<li><p>温和异常点和极端异常点</p>
</li>
</ul>
<p><img src="https://gitee.com/Olvi73/img/raw/master/Box-plot.png" alt="箱型图"></p>
<h4 id="一致性分析"><a href="#一致性分析" class="headerlink" title="一致性分析"></a>一致性分析</h4><p>数据不一致性是指数据的矛盾性、不相容性。直接对不一致的数据进行挖掘，可能会产生与实际相违背的挖掘结果。</p>
<p>在数据挖掘过程中，不一致的数据的产生主要发生在数据集成的过程中，可能是由于被挖掘数据来自于不同的数据源，对于重复存放的数据未能进行一致性更新造成的，比如两张表中都存储了用户的地址，在用户的地址发生改变时，如果只更新了一张表中的数据，那么这两张表中就有了不一致的数据。</p>
<h3 id="2-数据特征分析"><a href="#2-数据特征分析" class="headerlink" title="2. 数据特征分析"></a>2. 数据特征分析</h3><h4 id="1-分布分析"><a href="#1-分布分析" class="headerlink" title="1. 分布分析"></a>1. 分布分析</h4><h5 id="1-定量数据的分布分析"><a href="#1-定量数据的分布分析" class="headerlink" title="1. 定量数据的分布分析"></a>1. 定量数据的分布分析</h5><ol>
<li>求极差</li>
<li>决定组距和组数</li>
<li>决定分点</li>
<li>列出频率分布表</li>
<li>绘制频率分布直方图</li>
</ol>
<p><strong>要求</strong></p>
<ol>
<li>各组之间必须是相互排斥的</li>
<li>各组必须将所有的数据包括在内</li>
<li>各组的组宽最好相等</li>
</ol>
<h5 id="2-定性数据分析"><a href="#2-定性数据分析" class="headerlink" title="2. 定性数据分析"></a>2. 定性数据分析</h5><p>对于定性变量，常常根据变量的分类类型来分组。</p>
<h4 id="2-对比分析"><a href="#2-对比分析" class="headerlink" title="2. 对比分析"></a>2. 对比分析</h4><ol>
<li>绝对数比较</li>
<li>相对数比较<ol>
<li>结构相对数：将同一总体内的部分数值与全部数值进行对比求得比重，用以说明事物的性质、结构或质量</li>
<li>比例相对数：将同一总体内不同部分的数值进行对比，表明总体内各部分的比例关系。</li>
<li>比较相对数：将同一时期两个性质相同的指标数值进行对比，说明同类现象在不同空间条件下的数量对比关系。</li>
<li>强度相对数：将两个性质不同但有一定联系的总量指标进行对比，用以说明现象的强度、密度和普遍程度。</li>
<li>计划完成程度相对数：将某一时期实际完成数与计划完成数进行对比用以说明计划完成程度。</li>
<li>动态相对数：将同一现象在不同时期的指标数值进行对比，用以说明发展法向和变化速度，如发展速度、增长速度等。</li>
</ol>
</li>
</ol>
<h4 id="3-统计量分析"><a href="#3-统计量分析" class="headerlink" title="3. 统计量分析"></a>3. 统计量分析</h4><h5 id="1-集中趋势程度"><a href="#1-集中趋势程度" class="headerlink" title="1. 集中趋势程度"></a>1. 集中趋势程度</h5><ol>
<li>均值</li>
<li>中位数</li>
<li>众数</li>
</ol>
<h5 id="2-离中趋势度量"><a href="#2-离中趋势度量" class="headerlink" title="2. 离中趋势度量"></a>2. 离中趋势度量</h5><ol>
<li>极差</li>
<li>标准差</li>
<li>变异系数</li>
<li>四分位数间距</li>
</ol>
<h4 id="4-周期性分析"><a href="#4-周期性分析" class="headerlink" title="4. 周期性分析"></a>4. 周期性分析</h4><p>周期性分析是探索某个变量是否随着时间的变化而呈现出某种周期变化趋势。</p>
<h4 id="5-贡献度分析"><a href="#5-贡献度分析" class="headerlink" title="5. 贡献度分析"></a>5. 贡献度分析</h4><p>贡献度分析又称帕累托分析，它的原理是帕累托法则，又称20/80定律。同样的投入放在不同的地方会产生不同的效益，例如，对一个公司来讲，80%的利润常常来自于20%最畅销的产品，而其他80%的产品只产生了20%的利润。</p>
<h4 id="6-相关性分析"><a href="#6-相关性分析" class="headerlink" title="6. 相关性分析"></a>6. 相关性分析</h4><h5 id="1-直接绘制散点图"><a href="#1-直接绘制散点图" class="headerlink" title="1. 直接绘制散点图"></a>1. 直接绘制散点图</h5><p>判断两个变量是否具有线性相关关系最直观的方法 是直接绘制散点图</p>
<h5 id="2-绘制散点图矩阵"><a href="#2-绘制散点图矩阵" class="headerlink" title="2. 绘制散点图矩阵"></a>2. 绘制散点图矩阵</h5><h5 id="3-计算相关系数"><a href="#3-计算相关系数" class="headerlink" title="3. 计算相关系数"></a>3. 计算相关系数</h5><p>为了更加准确地描述变量之间的线性相关程度，可以通过相关系数的计算来进行相关分析</p>
<ol>
<li>Pearson相关系数（要求连续变量的取值服从正态分布）</li>
<li>Spearman秩相关系数（不服从正态分布的变量或等级变量之间的关系）</li>
<li>判定系数，判定系数是相关系数的平方，用$r^2$表示。$r^2$越接近1，表明x与y之间的相关性越强，$r^2$越接近0，表明x与y之间几乎没有直线相关关系</li>
</ol>
<h3 id="Python主要数据探索函数"><a href="#Python主要数据探索函数" class="headerlink" title="Python主要数据探索函数"></a>Python主要数据探索函数</h3><h4 id="1-基本统计特征函数"><a href="#1-基本统计特征函数" class="headerlink" title="1. 基本统计特征函数"></a>1. 基本统计特征函数</h4><table>
<thead>
<tr>
<th align="center">方法名</th>
<th align="center">函数功能</th>
<th align="center">所属库</th>
</tr>
</thead>
<tbody><tr>
<td align="center">sum()</td>
<td align="center">计算数据样本的总和</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">mean()</td>
<td align="center">计算数据样本的算术平均数</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">var()</td>
<td align="center">计算数据样本的方差</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">std()</td>
<td align="center">计算数据样本的标准差</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">corr()</td>
<td align="center">计算数据样本的Spearman(Pearson)相关系数矩阵</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">cov()</td>
<td align="center">计算数据样本的协方差矩阵</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">skew()</td>
<td align="center">样本值的偏度（三阶矩）</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">kurt()</td>
<td align="center">样本值的峰度（四阶矩）</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">describe()</td>
<td align="center">给出样本的基本描述（基本统计量如均值、标准差等）</td>
<td align="center">pandas</td>
</tr>
</tbody></table>
<h4 id="2-拓展统计特征函数"><a href="#2-拓展统计特征函数" class="headerlink" title="2. 拓展统计特征函数"></a>2. 拓展统计特征函数</h4><p>累计计算(<code>cum</code>)和滚动计算(<code>pd.rolling_</code>)，如<code>cumsum()</code> 依次给出前1,2，… n个数的和，<code>rolling(2).sum()</code>依次对相邻的两项求和</p>
<h4 id="3-统计绘图函数"><a href="#3-统计绘图函数" class="headerlink" title="3. 统计绘图函数"></a>3. 统计绘图函数</h4><table>
<thead>
<tr>
<th align="center">绘图函数名</th>
<th align="center">绘图函数功能</th>
<th align="center">所属工具箱</th>
</tr>
</thead>
<tbody><tr>
<td align="center">plot()</td>
<td align="center">绘制线性二维图，折线图</td>
<td align="center">Matplotlib/pandas</td>
</tr>
<tr>
<td align="center">pie()</td>
<td align="center">绘制饼图</td>
<td align="center">Matplotlib/pandas</td>
</tr>
<tr>
<td align="center">hist()</td>
<td align="center">绘制二维条形直方图，可显示数据的分配情形</td>
<td align="center">Matplotlib/pandas</td>
</tr>
<tr>
<td align="center">boxplot()</td>
<td align="center">绘制样本数据的箱型图</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">plot(logy = True)</td>
<td align="center">绘制y轴的对数图形</td>
<td align="center">pandas</td>
</tr>
<tr>
<td align="center">plot(yerr = error)</td>
<td align="center">绘制误差条形图</td>
<td align="center">pandas</td>
</tr>
</tbody></table>
<h4 id="4-代码实例"><a href="#4-代码实例" class="headerlink" title="4. 代码实例"></a>4. 代码实例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 代码3-10 计算两个列向量的相关系数</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">D = pd.DataFrame([range(<span class="number">1</span>, <span class="number">8</span>), range(<span class="number">2</span>, <span class="number">9</span>)])  <span class="comment"># 生成样本D，一行为1~7，一行为2~8</span></span><br><span class="line">print(D.corr(method=<span class="string">'spearman'</span>))  <span class="comment"># 计算相关系数矩阵</span></span><br><span class="line">S1 = D.loc[<span class="number">0</span>]  <span class="comment"># 提取第一行</span></span><br><span class="line">S2 = D.loc[<span class="number">1</span>]  <span class="comment"># 提取第二行</span></span><br><span class="line">print(S1.corr(S2, method=<span class="string">'pearson'</span>))  <span class="comment"># 计算S1、S2的相关系数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-11 计算6×5随机矩阵的协方差矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">D = pd.DataFrame(np.random.randn(<span class="number">6</span>, <span class="number">5</span>))  <span class="comment"># 产生6×5随机矩阵</span></span><br><span class="line">print(D.cov())  <span class="comment"># 计算协方差矩阵</span></span><br><span class="line">print(D[<span class="number">0</span>].cov(D[<span class="number">1</span>]))  <span class="comment"># 计算第一列和第二列的协方差</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-12 计算6×5随机矩阵的偏度（三阶矩）∕峰度（四阶矩）</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">D = pd.DataFrame(np.random.randn(<span class="number">6</span>, <span class="number">5</span>))  <span class="comment"># 产生6×5随机矩阵</span></span><br><span class="line">print(D.skew())  <span class="comment"># 计算偏度</span></span><br><span class="line">print(D.kurt())  <span class="comment"># 计算峰度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-13 6×5随机矩阵的describe</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">D = pd.DataFrame(np.random.randn(<span class="number">6</span>, <span class="number">5</span>))  <span class="comment"># 产生6×5随机矩阵</span></span><br><span class="line">print(D.describe())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-14 pandas累积统计特征函数、移动窗口统计函数示例</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">D=pd.Series(range(<span class="number">0</span>, <span class="number">20</span>))  <span class="comment"># 构造Series，内容为0~19共20个整数</span></span><br><span class="line">print(D.cumsum())  <span class="comment"># 给出前n项和</span></span><br><span class="line">print(D.rolling(<span class="number">2</span>).sum())  <span class="comment"># 依次对相邻两项求和</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-15 绘图之前需要加载的代码</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  <span class="comment"># 导入绘图库</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.figure(figsize = (<span class="number">7</span>, <span class="number">5</span>))  <span class="comment"># 创建图像区域，指定比例</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-16 绘制一条蓝色的正弦虚线</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.linspace(<span class="number">0</span>,<span class="number">2</span>*np.pi,<span class="number">50</span>)  <span class="comment"># x坐标输入</span></span><br><span class="line">y = np.sin(x)  <span class="comment"># 计算对应x的正弦值</span></span><br><span class="line">plt.plot(x, y, <span class="string">'bp--'</span>)  <span class="comment"># 控制图形格式为蓝色带星虚线，显示正弦曲线</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-17 绘制饼图</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># The slices will be ordered and plotted counter-clockwise.</span></span><br><span class="line">labels = <span class="string">'Frogs'</span>, <span class="string">'Hogs'</span>, <span class="string">'Dogs'</span>, <span class="string">'Logs'</span>  <span class="comment"># 定义标签</span></span><br><span class="line">sizes = [<span class="number">15</span>, <span class="number">30</span>, <span class="number">45</span>, <span class="number">10</span>]  <span class="comment"># 每一块的比例</span></span><br><span class="line">colors = [<span class="string">'yellowgreen'</span>, <span class="string">'gold'</span>, <span class="string">'lightskyblue'</span>, <span class="string">'lightcoral'</span>]  <span class="comment"># 每一块的颜色</span></span><br><span class="line">explode = (<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0</span>)  <span class="comment"># 突出显示，这里仅仅突出显示第二块（即'Hogs'）</span></span><br><span class="line"></span><br><span class="line">plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct=<span class="string">'%1.1f%%'</span>, shadow=<span class="literal">True</span>, startangle=<span class="number">90</span>)</span><br><span class="line">plt.axis(<span class="string">'equal'</span>)  <span class="comment"># 显示为圆（避免比例压缩为椭圆）</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-18 绘制二维条形直方图</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.random.randn(<span class="number">1000</span>)  <span class="comment"># 1000个服从正态分布的随机数</span></span><br><span class="line">plt.hist(x, <span class="number">10</span>)  <span class="comment"># 分成10组进行绘制直方图</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-19 绘制箱型图</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">x = np.random.randn(<span class="number">1000</span>)  <span class="comment"># 1000个服从正态分布的随机数</span></span><br><span class="line">D = pd.DataFrame([x, x+<span class="number">1</span>]).T  <span class="comment"># 构造两列的DataFrame</span></span><br><span class="line">D.plot(kind = <span class="string">'box'</span>)  <span class="comment"># 调用Series内置的绘图方法画图，用kind参数指定箱型图box</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-20 使用plot(logy = True)函数进行绘图</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">x = pd.Series(np.exp(np.arange(<span class="number">20</span>)))  <span class="comment"># 原始数据</span></span><br><span class="line">plt.figure(figsize = (<span class="number">8</span>, <span class="number">9</span>))  <span class="comment"># 设置画布大小 </span></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">x.plot(label = <span class="string">u'原始数据图'</span>, legend = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">x.plot(logy = <span class="literal">True</span>, label = <span class="string">u'对数数据图'</span>, legend = <span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码3-21 绘制误差棒图</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">error = np.random.randn(<span class="number">10</span>)  <span class="comment"># 定义误差列</span></span><br><span class="line">y = pd.Series(np.sin(np.arange(<span class="number">10</span>)))  <span class="comment"># 均值数据列</span></span><br><span class="line">y.plot(yerr = error)  <span class="comment"># 绘制误差图</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="第四章-数据预处理-P75"><a href="#第四章-数据预处理-P75" class="headerlink" title="第四章 数据预处理 P75"></a>第四章 数据预处理 P75</h2><p><img src="https://gitee.com/Olvi73/img/raw/master/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.jpg" alt="数据预处理"></p>
<h3 id="1-数据清洗"><a href="#1-数据清洗" class="headerlink" title="1. 数据清洗"></a>1. 数据清洗</h3><p>数据清洗主要是删除原始数据集中的无关数据、重复数据，平滑噪声数据，筛选掉与挖掘主题无关的数据，处理缺失值、异常值等</p>
<h4 id="1-缺失值处理"><a href="#1-缺失值处理" class="headerlink" title="1. 缺失值处理"></a>1. 缺失值处理</h4><p>处理方法可分为三类：删除记录、数据插补和不处理</p>
<table>
<thead>
<tr>
<th>插补方法</th>
<th>方法描述</th>
</tr>
</thead>
<tbody><tr>
<td>均值、中位数、众数插补</td>
<td>根据属性值的类型，用该属性取值的平均数、中位数、众数进行插补</td>
</tr>
<tr>
<td>使用固定值</td>
<td>将缺失的属性值用一个常量替换</td>
</tr>
<tr>
<td>最近临插补</td>
<td>在记录中找到与缺失样本最接近的样本的该属性卡值插补</td>
</tr>
<tr>
<td>回归方法</td>
<td>对带有缺失值的变量，根据已有数据和与其有关的其他变量（因变量）的数据建立拟合模型来预测确实的属性值</td>
</tr>
<tr>
<td>插值法</td>
<td>插值法是利用已知点建立合适的插值函数$f(x)$，未知数由对应点$x_i$求出的函数值$f(x_i)$近似代替</td>
</tr>
</tbody></table>
<h5 id="1-拉格朗日插值法"><a href="#1-拉格朗日插值法" class="headerlink" title="1. 拉格朗日插值法"></a>1. 拉格朗日插值法</h5><h5 id="2-牛顿插值法"><a href="#2-牛顿插值法" class="headerlink" title="2. 牛顿插值法"></a>2. 牛顿插值法</h5><h4 id="2-异常值处理"><a href="#2-异常值处理" class="headerlink" title="2. 异常值处理"></a>2. 异常值处理</h4><table>
<thead>
<tr>
<th>异常值处理方法</th>
<th>方法描述</th>
</tr>
</thead>
<tbody><tr>
<td>删除含有异常值的记录</td>
<td>直接将含有异常值的记录删除</td>
</tr>
<tr>
<td>视为缺失值</td>
<td>将异常值视为缺失值，利用缺失值处理的方法进行处理</td>
</tr>
<tr>
<td>平均值修正</td>
<td>可用前后两个观测值修正该异常值</td>
</tr>
<tr>
<td>不处理</td>
<td>直接在具有异常值的数据集上进行挖掘建模</td>
</tr>
</tbody></table>
<h3 id="2-数据集成"><a href="#2-数据集成" class="headerlink" title="2. 数据集成"></a>2. 数据集成</h3><p>数据挖掘需要的数据往往分布在不同的数据源中，数据集成就是将多个数据源合并存放在一个一致的数据储存位置（如数据仓库）中的过程。</p>
<h4 id="1-实体识别"><a href="#1-实体识别" class="headerlink" title="1. 实体识别"></a>1. 实体识别</h4><ol>
<li>同名异义：数据源A中的属性ID和数据源B三的属性ID分别描述的是菜品编号和订单编号，即描述的是不同的实体</li>
<li>异名同义：数据源A中的sales_dt和数据源B中的sales_date都是描述销售日期的</li>
<li>单位不统一：描述同一个实体时分别用的是国际单位和中国传统的计量单位</li>
</ol>
<h4 id="2-冗余属性识别"><a href="#2-冗余属性识别" class="headerlink" title="2. 冗余属性识别"></a>2. 冗余属性识别</h4><ol>
<li>同一属性多次出现</li>
<li>同一属性命名不一致导致重复</li>
</ol>
<h4 id="3-数据变换"><a href="#3-数据变换" class="headerlink" title="3. 数据变换"></a>3. 数据变换</h4><p>主要是对数据进行规范化处理，将数据转换成“适当的”形式，以适用于挖掘任务和算法的需要。</p>
<ol>
<li><p>简单函数变换，对原始数据进行某些数学函数变换，包括平方、取对数、差分运算等</p>
</li>
<li><p>规范化</p>
<ol>
<li><p>最小-最大规范化，也叫离差标准化，对原始数据的线性变换，将数值映射到[0,1]之间。</p>
<p>$$ x^*=\frac{(x-min)}{(max-min)} $$</p>
</li>
<li><p>0-均值规范化，也叫标准差标准化，经过处理的数据均值为0，标准差为1。</p>
<p>$$ x^*= \frac{x-\overline{x}}{σ} $$</p>
</li>
<li><p>小数定标规范化，通过移动属性值的小数位数，将属性值映射到[-1,1]之间，移动的小数位数取决于属性值绝对值的最大值</p>
<p>$$ x^*=\frac{x}{10^k} $$</p>
</li>
</ol>
</li>
<li><p>连续属性离散化，如某些分类算法，ID3算法、Apriori算法，要求数据是分类属性形式。</p>
<ol>
<li>离散化的过程，连续属性离散化就是在数据的取值范围内设定若干个离散的划分点，将取值范围划分为一些离散化的区间，最后用不同的符号或整数值代表落在每个子区间中的数据值</li>
<li>常用的离散化方法，等宽法和（一维）聚类。</li>
</ol>
<ul>
<li>等宽法，将属性的值域分成具有相同宽度的区间，区间的个数由数据本身的特点决定或者用户指定，类似与制作频率分布表</li>
<li>等频法，将相同数量的记录放进每个区间<ul>
<li>这两种方法简单，易于操作，但都需要认为规定划分区间的个数。同时，等宽法缺点在于它对离群点比较敏感，倾向于不均匀地把属性值分布到各个区间。有些区间包含许多数据，而另外一些区间的数据极少，这样会严重损坏建立的决策模型。等频法虽然避免了上述问题的产生，却可能将相同的数据值分布到不同的区间，以满足每个区间中固定的数据个数</li>
</ul>
</li>
<li>基于聚类分析的方法，一维聚类方法包括两个步骤：首先将连续属性的值用聚类算法（如K-Means算法)进行聚类，然后再将聚类得到的簇进行处理，合并到一个簇的连续属性值做同一标记。聚类分析的离散化方法也需要用户制定簇的个数，从而决定产生的区间数。</li>
</ul>
</li>
<li><p>属性构造，利用已有的属性集构造新的属性，并加入到现有的属性集合中。</p>
</li>
<li><p>小波变换 P(88)，信号分析手段</p>
</li>
</ol>
<h3 id="3-数据规约"><a href="#3-数据规约" class="headerlink" title="3. 数据规约"></a>3. 数据规约</h3><p>在大数据集上进行复杂的数据分析和挖掘需要很长时间。数据规约产生更小且保持原数据完整性的新数据集，在规约后的数据集上进行分析和挖掘将提高效率。</p>
<p><strong>意义</strong></p>
<ol>
<li>降低无效、错误数据对建模的影响，提高建模的准确性</li>
<li>少量却具有代表性的数据将大幅缩减数据挖掘的时间</li>
<li>降低储存数据的成本</li>
</ol>
<h4 id="1-属性规约"><a href="#1-属性规约" class="headerlink" title="1. 属性规约"></a>1. 属性规约</h4><p>属性规约通过属性合并创建新属性维数，或者通过直接删除不相关的属性（维）来减少数据维数，从而提高数据挖掘的效率，降低计算成本。属性规约的目标是寻找最小的属性子集并确保新数据子集的概率分布尽可能接近原来的数据集的概率分布。</p>
<table>
<thead>
<tr>
<th>属性规约方法</th>
<th>方法描述</th>
<th>方法解析</th>
</tr>
</thead>
<tbody><tr>
<td>合并属性</td>
<td>将一些旧属性合并为新属性</td>
<td>初始属性集：{$A_1,A_2,A_3,B_1,B_2,B_3,C$},{$A_1,A_2,A_3$}-&gt;$A$ {$B_1,B_2,B_3$}-&gt;$B$ 规约后属性集{$A,B,C$}</td>
</tr>
<tr>
<td>逐步向前选择</td>
<td>从一个空属性集开始，每次从原来属性集合中选择一个当前最优的属性添加到当前属性子集中。直到无法选出最优属性或满足一定阈值约束为止</td>
<td>初始属性集：{$A_1,A_2,A_3,A_4,A_5,A_6$},{}-&gt;{$A_1$}-&gt;{$A_1,A_4$} 规约后属性集{$A_1,A_4,A_6$}</td>
</tr>
<tr>
<td>逐步向后删除</td>
<td>从一个全属性集开始，每次从当前属性子集中选择一个当前最差的属性并将其从当前属性子集中消去。直到无法选出最差属性为止或满足一定阈值约束为止</td>
<td>初始属性集：{$A_1,A_2,A_3,A_4,A_5,A_6$},{$A_1,A_3,A_4,A_5,A_6$}-&gt;{$A_1,A_4,A_5,A_6$}   规约后属性集{$A_1,A_4,A_6$}</td>
</tr>
<tr>
<td>决策树归纳</td>
<td>利用决策树的归纳方法对初始数据进行分类归纳学习，获得一个初始决策树，所有没有出现在这个决策树上的属性均可认为是无关属性，因此将这些属性从初始集合中删除，就可以获得一个较优的属性子集</td>
<td>略</td>
</tr>
<tr>
<td>主成分分析</td>
<td>用较少的变量去解释原始数据中的大部分变量，即将许多线性相关性很高的变量转化成彼此互相独立或不相关的变量</td>
<td>略</td>
</tr>
</tbody></table>
<p>逐步向前选择、逐步向后删除和决策树归纳是属于直接删除不相关属性（维）的方法。主成分分析法是一种用于连续属性的数据降维方法，它构造了原始数据的一个正交变换，新空间的基底去除了原始空间基底下数据的相关性，只需要使用少数新变量就能解释原始数据中的大部分变异。</p>
<p>在应用中，通常是选出比原始变量个数少，能解释大部分数据中的变量的几个新变量，即所谓主成分，来代替原始变量进行建模。</p>
<h5 id="主成分分析计算步骤"><a href="#主成分分析计算步骤" class="headerlink" title="主成分分析计算步骤"></a>主成分分析计算步骤</h5><p>主成分分析的步骤：中心化数据集-计算协方差矩阵-计算特征根-计算主成分矩阵-得到降维后的数据集</p>
<ol>
<li><p>设原始变量$X_1,X_2,…,X_p$的$n$次观测数据矩阵为式<br>$$<br>X=\begin{Bmatrix}<br>X_{11} &amp; X_{12} &amp; \dots &amp; X_{13} \\<br>X_{21} &amp; X_{22} &amp; \dots &amp; X_{23} \\<br>\dots &amp; \dots &amp; \dots &amp; \dots \\<br>X_{n1} &amp; X_{n2} &amp; \dots &amp; X_{np} \\<br>\end{Bmatrix}=(X_1,X_2,\dots,X_P)<br>$$</p>
</li>
<li><p>将数据矩阵按列进行中心标准化。</p>
</li>
<li><p>求相关系数矩阵 $\mathbf{R}$ ，$ \mathbf{R} = (r_{ij})_ {p\times p} $ ， $r_{ij}$定义为式，其中$r_{ij}=r_{ji},r_{ij}=1$<br>$$<br>r_{rj}=<br>\sum\nolimits_{k=1}^n (x_{ki}-\overline{x_i})(x_{kj}-\overline{x_j})<br>/<br>\sqrt{<br>\sum\nolimits_{k=1}^n (x_{ki}-\overline{x_i})^2<br>\sum\nolimits_{k=1}^n (x_{kj}-\overline{x_j})^2<br>}<br>$$</p>
</li>
<li><p>求$\mathbf{R}$的特征方程 $ det(\mathbf{R}-λ\mathbf{E})=0 $ 的特征根$λ_1\geλ_2\ge…λ_p&gt;0$</p>
</li>
<li><p>确定主成分个数，α根据实际问题确定，一般取80%<br>$$<br>m:<br>\frac{\sum\nolimits_{i=1}^m \lambda_i}<br>{\sum\nolimits_{i=1}^p \lambda_i}<br>\ge<br>\alpha<br>$$</p>
</li>
<li><p>计算m个相应的单位特征向量，如式<br>$$<br> \mathbf{\beta_1}=\begin{pmatrix}<br> \beta_1 \\ \beta_2 \\ …\\ \beta_{p1}<br> \end{pmatrix}<br> ,<br> \mathbf{\beta_2}=\begin{pmatrix}<br> \beta_{12} \\ \beta_{22} \\ …\\ \beta_{p2}<br> \end{pmatrix}<br> ,<br> \mathbf{\beta_m}=\begin{pmatrix}<br> \beta_{1m} \\ \beta_{2m} \\ …\\ \beta_{pm}<br> \end{pmatrix}<br>$$</p>
</li>
<li><p>计算主成分，如式<br>$$<br>Z_i=\beta_{1i}X_1+\beta_{2i}X_2+…+\beta_{pi}X_p (i=1,2,…,m)<br>$$</p>
</li>
</ol>
<p>python中主成分分析函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.PCA(n_components=<span class="literal">None</span>, copy=<span class="literal">True</span>, whiten=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数名称</th>
<th>意义</th>
<th>类型</th>
</tr>
</thead>
<tbody><tr>
<td>n_components</td>
<td>PCA算法中索要保留的主成分个数n，就是保留下来的特征个数n</td>
<td>int/str</td>
</tr>
<tr>
<td>copy</td>
<td>表示是否在运行算法时，将原始训练数据复制一份</td>
<td>bool</td>
</tr>
<tr>
<td>whiten</td>
<td>白化，使得每个特征具有相同的方差</td>
<td>bool</td>
</tr>
</tbody></table>
<h4 id="2-数值规约"><a href="#2-数值规约" class="headerlink" title="2. 数值规约"></a>2. 数值规约</h4><p>数值规约通过选择代替的、较小的数据来减少数据量，包括有参数方法和无参数方法两类。有参数方法是使用一个模型来评估数据，只需存放参数，而不需要存放实际数据，例如回归（线性回归和多元回归）和对数线性模型（近似离散属性集中的多维概率分布）。无参数方法就需要存放实际数据，如直方图、聚类、抽样（采样）。</p>
<ol>
<li>直方图</li>
<li>聚类</li>
<li>抽样<ul>
<li>常用抽样方法<ol>
<li>s个样本无放回简单随机抽样</li>
<li>s个样本有放回地简单随机抽样</li>
<li>聚类抽样</li>
<li>分层抽样</li>
</ol>
</li>
</ul>
</li>
<li>参数回归</li>
</ol>
<h3 id="4-Python主要数据预处理函数"><a href="#4-Python主要数据预处理函数" class="headerlink" title="4. Python主要数据预处理函数"></a>4. Python主要数据预处理函数</h3><table>
<thead>
<tr>
<th>函数名</th>
<th>函数功能</th>
<th>所属拓展库</th>
</tr>
</thead>
<tbody><tr>
<td>interpolate</td>
<td>一维、高维数据插值</td>
<td>SciPy</td>
</tr>
<tr>
<td>unique</td>
<td>去除数据中的重复元素，得到单值元素列表，它是对象的方法名</td>
<td>pandas/Numpy</td>
</tr>
<tr>
<td>isnull</td>
<td>判断是否空值</td>
<td>pandas</td>
</tr>
<tr>
<td>notnull</td>
<td>判断是否非空值</td>
<td>pandas</td>
</tr>
<tr>
<td>PCA</td>
<td>对指标变量矩阵进行主成分分析</td>
<td>Scikit-learn</td>
</tr>
<tr>
<td>random</td>
<td>生成随机矩阵</td>
<td>Numpy</td>
</tr>
</tbody></table>
<h4 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 代码4-8 求向量D中的单值元素，并返回相关索引</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">D = pd.Series([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line">D.unique()</span><br><span class="line">np.unique(D)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码 4-9 对一个10×4维的随机矩阵进行主成分分析</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">D = np.random.rand(<span class="number">10</span>,<span class="number">4</span>)</span><br><span class="line">pca = PCA()</span><br><span class="line">pca.fit(D)</span><br><span class="line">pca.components_  <span class="comment"># 返回模型的各个特征向量</span></span><br><span class="line">pca.explained_variance_ratio_  <span class="comment"># 返回各个成分各自的方差百分比</span></span><br></pre></td></tr></table></figure>

<h2 id="第五章-挖掘建模-P102"><a href="#第五章-挖掘建模-P102" class="headerlink" title="第五章 挖掘建模 P102"></a>第五章 挖掘建模 P102</h2><h3 id="1-分类与预测"><a href="#1-分类与预测" class="headerlink" title="1. 分类与预测"></a>1. 分类与预测</h3><h4 id="1-实现过程"><a href="#1-实现过程" class="headerlink" title="1. 实现过程"></a>1. 实现过程</h4><ol>
<li>分类是构造一个分类模型，输入样本的属性值，输出对应的类别，将每个样本映射到预先定义好的类别。分类模型建立在已有类标记的数据集上，模型在已有样本上的准确率可以方便的绩，所以分类属于有监督的学习。</li>
<li>预测，预测是建立两种或两种以上变量间相互依赖的函数模型，然后进行预测或控制</li>
<li>实现过程，分类为和预测的实现过程类似，以分类模型为例。</li>
</ol>
<p><img src="https://gitee.com/Olvi73/img/raw/master/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%AD%A5%E9%AA%A4.jpg" alt="分类模型的实现步骤"></p>
<h4 id="2-常用的分类与预测算法"><a href="#2-常用的分类与预测算法" class="headerlink" title="2. 常用的分类与预测算法"></a>2. 常用的分类与预测算法</h4><table>
<thead>
<tr>
<th>算法名称</th>
<th>算法描述</th>
</tr>
</thead>
<tbody><tr>
<td>回归分析</td>
<td>回归分析是确定预测属性（数值型）与其他变量间相互依赖的定量关系最常用的统计学方法，包括线性回归、非线性回归、Logistic回归、岭回归、主成分回归、最小二乘回归等模型</td>
</tr>
<tr>
<td>决策树</td>
<td>决策树采用自顶向下的递归方式，在内部节点进行属性值的比较，并根据不同的属性值从该节点向下分支，最终得到的叶节点是学习划分的类</td>
</tr>
<tr>
<td>人工神经网络</td>
<td>人工神经网络是一种模型大脑神经网络结构和功能而建立的信息处理系统，表示神经网络的输入与输出变量之间的关系的模型</td>
</tr>
<tr>
<td>贝叶斯网络</td>
<td>贝叶斯网络又称信度网络，是Bayes方法的扩展，是目前不确定知识表达和推理领域最有效的理论模型之一</td>
</tr>
<tr>
<td>支持向量机</td>
<td>支持向量机是一种通过某种非现行映射，把低维的非现行可分转化为高维的线性可分，在高维空间进行线性分析的算法</td>
</tr>
</tbody></table>
<h4 id="3-回归分析"><a href="#3-回归分析" class="headerlink" title="3. 回归分析"></a>3. 回归分析</h4><table>
<thead>
<tr>
<th>回归模型名称</th>
<th>适用条件</th>
<th>算法描述</th>
</tr>
</thead>
<tbody><tr>
<td>线性回归</td>
<td>因变量与自变量是线性关系</td>
<td>对一个或多个自变量与因变量之间的线性关系进行建模，可用最小二乘法求解模型系数</td>
</tr>
<tr>
<td>非线性回归</td>
<td>因变量与自变量之间不都是线性关系</td>
<td>对一个或多个自变量和因变量之间的非线性关系进行建模。如果可转化为线性关系则用线性关系求解，否则用非线性最小二乘方法求解</td>
</tr>
<tr>
<td>Logistic回归</td>
<td>一般是因变量的有1-0（是否）两种取值</td>
<td>是广义线性回归模型的特例，利用Logistic函数将因变量的取值范围控制在的0和1之间，表示取值1的概率</td>
</tr>
<tr>
<td>岭回归</td>
<td>参与建模的自变量之间具有多重共线性</td>
<td>是一种改进最小二乘估计的方法</td>
</tr>
<tr>
<td>主成分回归</td>
<td>参与建模的自变量之间具有多重共线性</td>
<td>根据主成分分析思想，对最小二乘法的一种改进，它是参数估计的一种有偏估计，可消除自变量之间的多重共线性</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码5-1 Logistic回归</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="keyword">as</span> LR</span><br><span class="line"><span class="comment"># 参数初始化</span></span><br><span class="line">filename = <span class="string">'../data/bankloan.xls'</span></span><br><span class="line">data = pd.read_excel(filename)</span><br><span class="line">x = data.iloc[:,:<span class="number">8</span>].as_matrix()</span><br><span class="line">y = data.iloc[:,<span class="number">8</span>].as_matrix()</span><br><span class="line"></span><br><span class="line">lr = LR()  <span class="comment"># 建立逻辑回归模型</span></span><br><span class="line">lr.fit(x, y)  <span class="comment"># 用筛选后的特征数据来训练模型</span></span><br><span class="line">print(<span class="string">'模型的平均准确度为：%s'</span> % lr.score(x, y))</span><br></pre></td></tr></table></figure>

<h4 id="4-决策树"><a href="#4-决策树" class="headerlink" title="4. 决策树"></a>4. 决策树</h4><blockquote>
<p>熵（entropy）</p>
</blockquote>
<table>
<thead>
<tr>
<th>决策树算法</th>
<th>算法描述</th>
</tr>
</thead>
<tbody><tr>
<td>ID3算法</td>
<td>其核心是在决策树的各级节点上，使用信息增益方法作为属性的选择标准，来帮助确定生成每个节点时所应采用的合适属性</td>
</tr>
<tr>
<td>C4.5算法</td>
<td>相对于ID3算法的重要改进是使用信息增益率来选择节点属性。C4.5算法可以克服ID3算法存在的不足：ID3算法只适用于离散的描述属性，而C4.5算法既能够处理离散的描述属性，也可以处理连续的描述属性</td>
</tr>
<tr>
<td>CART算法</td>
<td>CART决策树是一种十分有效的非参数分类和回归方法，通过构建树、修剪树、评估树来构建一个二叉树。当中节点是连续变量时，该树为回归树，当终节点是分类变量时，该树为分类树</td>
</tr>
</tbody></table>
<ul>
<li>ID3算法实现步骤<ol>
<li>对当前样本集合，计算所有属性的信息增益</li>
<li>选择信息增益最大的属性作为测试属性，把测试属性取值相同的样本划分为同一个样本子集</li>
<li>若子样本集的类别属性只含有单个属性，则分支为叶子节点，判断其属性值并标上相应的符号，然后返回调用处；否则对子样本集递归调用本算法</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码5-2 决策树</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 参数初始化</span></span><br><span class="line">filename = <span class="string">'../data/sales_data.xls'</span></span><br><span class="line">data = pd.read_excel(filename, index_col = <span class="string">u'序号'</span>)  <span class="comment"># 导入数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据是类别标签，要将它转换为数据</span></span><br><span class="line"><span class="comment"># 用1来表示“好”“是”“高”这三个属性，用-1来表示“坏”“否”“低”</span></span><br><span class="line">data[data == <span class="string">u'好'</span>] = <span class="number">1</span></span><br><span class="line">data[data == <span class="string">u'是'</span>] = <span class="number">1</span></span><br><span class="line">data[data == <span class="string">u'高'</span>] = <span class="number">1</span></span><br><span class="line">data[data != <span class="number">1</span>] = <span class="number">-1</span></span><br><span class="line">x = data.iloc[:,:<span class="number">3</span>].astype(int)</span><br><span class="line">y = data.iloc[:,<span class="number">3</span>].astype(int)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier <span class="keyword">as</span> DTC</span><br><span class="line">dtc = DTC(criterion=<span class="string">'entropy'</span>)  <span class="comment"># 建立决策树模型，基于信息熵</span></span><br><span class="line">dtc.fit(x, y)  <span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入相关函数，可视化决策树。</span></span><br><span class="line"><span class="comment"># 导出的结果是一个dot文件，需要安装Graphviz才能将它转换为pdf或png等格式。</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line">x = pd.DataFrame(x)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">string1 = '''</span></span><br><span class="line"><span class="string">edge [fontname="NSimSun"];</span></span><br><span class="line"><span class="string">node [ fontname="NSimSun" size="15,15"];</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">''' </span></span><br><span class="line"><span class="string">string2 = '&#125;'</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"../tmp/tree.dot"</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    export_graphviz(dtc, feature_names = x.columns, out_file = f)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">from IPython.display import Image  </span></span><br><span class="line"><span class="string">from sklearn import tree</span></span><br><span class="line"><span class="string">import pydotplus </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">dot_data = tree.export_graphviz(dtc, out_file=None,  #regr_1 是对应分类器</span></span><br><span class="line"><span class="string">                         feature_names=data.columns[:3],   #对应特征的名字</span></span><br><span class="line"><span class="string">                         class_names=data.columns[3],    #对应类别的名字</span></span><br><span class="line"><span class="string">                         filled=True, rounded=True,  </span></span><br><span class="line"><span class="string">                         special_characters=True)  </span></span><br><span class="line"><span class="string">graph = pydotplus.graph_from_dot_data(dot_data)  </span></span><br><span class="line"><span class="string">graph.write_png('../tmp/example.png')    #保存图像</span></span><br><span class="line"><span class="string">Image(graph.create_png()) </span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>

<h4 id="5-人工神经网络"><a href="#5-人工神经网络" class="headerlink" title="5. 人工神经网络"></a>5. 人工神经网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 参数初始化</span></span><br><span class="line">inputfile = <span class="string">'../data/sales_data.xls'</span></span><br><span class="line">data = pd.read_excel(inputfile, index_col = <span class="string">u'序号'</span>)  <span class="comment"># 导入数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据是类别标签，要将它转换为数据</span></span><br><span class="line"><span class="comment"># 用1来表示“好”“是”“高”这三个属性，用0来表示“坏”“否”“低”</span></span><br><span class="line">data[data == <span class="string">u'好'</span>] = <span class="number">1</span></span><br><span class="line">data[data == <span class="string">u'是'</span>] = <span class="number">1</span></span><br><span class="line">data[data == <span class="string">u'高'</span>] = <span class="number">1</span></span><br><span class="line">data[data != <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">x = data.iloc[:,:<span class="number">3</span>].astype(int)</span><br><span class="line">y = data.iloc[:,<span class="number">3</span>].astype(int)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</span><br><span class="line"></span><br><span class="line">model = Sequential()  <span class="comment"># 建立模型</span></span><br><span class="line">model.add(Dense(input_dim = <span class="number">3</span>, units = <span class="number">10</span>))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))  <span class="comment"># 用relu函数作为激活函数，能够大幅提供准确度</span></span><br><span class="line">model.add(Dense(input_dim = <span class="number">10</span>, units = <span class="number">1</span>))</span><br><span class="line">model.add(Activation(<span class="string">'sigmoid'</span>))  <span class="comment"># 由于是0-1输出，用sigmoid函数作为激活函数</span></span><br><span class="line"></span><br><span class="line">model.compile(loss = <span class="string">'binary_crossentropy'</span>, optimizer = <span class="string">'adam'</span>)</span><br><span class="line"><span class="comment"># 编译模型。由于我们做的是二元分类，所以我们指定损失函数为binary_crossentropy，以及模式为binary</span></span><br><span class="line"><span class="comment"># 另外常见的损失函数还有mean_squared_error、categorical_crossentropy等，请阅读帮助文件。</span></span><br><span class="line"><span class="comment"># 求解方法我们指定用adam，还有sgd、rmsprop等可选</span></span><br><span class="line"></span><br><span class="line">model.fit(x, y, epochs = <span class="number">1000</span>, batch_size = <span class="number">10</span>)  <span class="comment"># 训练模型，学习一千次</span></span><br><span class="line">yp = model.predict_classes(x).reshape(len(y))  <span class="comment"># 分类预测</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cm_plot <span class="keyword">import</span> *  <span class="comment"># 导入自行编写的混淆矩阵可视化函数</span></span><br><span class="line">cm_plot(y,yp).show()  <span class="comment"># 显示混淆矩阵可视化结果</span></span><br></pre></td></tr></table></figure>

<h3 id="2-聚类分析"><a href="#2-聚类分析" class="headerlink" title="2. 聚类分析"></a>2. 聚类分析</h3><h4 id="K-Means聚类分析"><a href="#K-Means聚类分析" class="headerlink" title="K-Means聚类分析"></a>K-Means聚类分析</h4><p>K-Means算法是典型的基于举例的非层次聚类算法，在最小化误差函数的基础上将数据划分为预定的磊K，采用距离作为相似性评价指标，即认为两个对象的距离越近，相似度越大</p>
<h5 id="1-算法过程"><a href="#1-算法过程" class="headerlink" title="1. 算法过程"></a>1. 算法过程</h5><ol>
<li>从$n$个样本数据中随机选取$k$个对象作为初始的聚类中心。</li>
<li>分别计算每个样本到各个聚类中心的距离，将对象分配到距离最近的聚类中。</li>
<li>所有对象分配完成后，重新计算$k$个聚类的中心。</li>
<li>与前一次计算得到的$k$个聚类中心比较，如果聚类中心发生变化，转至步骤2，否则继续步骤5</li>
<li>当质心不发生变化时，停止并输出聚类结果。</li>
</ol>
<h5 id="2-代码实例"><a href="#2-代码实例" class="headerlink" title="2. 代码实例"></a>2. 代码实例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 参数初始化</span></span><br><span class="line">inputfile = <span class="string">'../data/consumption_data.xls'</span>  <span class="comment"># 销量及其他属性数据</span></span><br><span class="line">outputfile = <span class="string">'../tmp/data_type.xls'</span>  <span class="comment"># 保存结果的文件名</span></span><br><span class="line">k = <span class="number">3</span>  <span class="comment"># 聚类的类别</span></span><br><span class="line">iteration = <span class="number">500</span>  <span class="comment"># 聚类最大循环次数</span></span><br><span class="line">data = pd.read_excel(inputfile, index_col = <span class="string">'Id'</span>)  <span class="comment"># 读取数据</span></span><br><span class="line">data_zs = <span class="number">1.0</span>*(data - data.mean())/data.std()  <span class="comment"># 数据标准化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">model = KMeans(n_clusters = k, n_jobs = <span class="number">4</span>, max_iter = iteration,random_state=<span class="number">1234</span>)  <span class="comment"># 分为k类，并发数4</span></span><br><span class="line">model.fit(data_zs)  <span class="comment"># 开始聚类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 简单打印结果</span></span><br><span class="line">r1 = pd.Series(model.labels_).value_counts()  <span class="comment"># 统计各个类别的数目</span></span><br><span class="line">r2 = pd.DataFrame(model.cluster_centers_)  <span class="comment"># 找出聚类中心</span></span><br><span class="line">r = pd.concat([r2, r1], axis = <span class="number">1</span>)  <span class="comment"># 横向连接（0是纵向），得到聚类中心对应的类别下的数目</span></span><br><span class="line">r.columns = list(data.columns) + [<span class="string">'类别数目'</span>]  <span class="comment"># 重命名表头</span></span><br><span class="line">print(r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 详细输出原始数据及其类别</span></span><br><span class="line">r = pd.concat([data, pd.Series(model.labels_, index = data.index)], axis = <span class="number">1</span>)   <span class="comment"># 详细输出每个样本对应的类别</span></span><br><span class="line">r.columns = list(data.columns) + [<span class="string">'聚类类别'</span>]  <span class="comment"># 重命名表头</span></span><br><span class="line">r.to_excel(outputfile)  <span class="comment"># 保存结果</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">density_plot</span><span class="params">(data)</span>:</span>  <span class="comment"># 自定义作图函数</span></span><br><span class="line">  <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">  plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">  plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">  p = data.plot(kind=<span class="string">'kde'</span>, linewidth = <span class="number">2</span>, subplots = <span class="literal">True</span>, sharex = <span class="literal">False</span>)</span><br><span class="line">  [p[i].set_ylabel(<span class="string">u'密度'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(k)]</span><br><span class="line">  plt.legend()</span><br><span class="line">  <span class="keyword">return</span> plt</span><br><span class="line"></span><br><span class="line">pic_output = <span class="string">'../tmp/pd'</span>  <span class="comment"># 概率密度图文件名前缀</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">  density_plot(data[r[<span class="string">u'聚类类别'</span>]==i]).savefig(<span class="string">u'%s%s.png'</span> %(pic_output, i))</span><br></pre></td></tr></table></figure>

<h3 id="3-关联规则"><a href="#3-关联规则" class="headerlink" title="3. 关联规则"></a>3. 关联规则</h3><h4 id="Apriori算法"><a href="#Apriori算法" class="headerlink" title="Apriori算法"></a>Apriori算法</h4><p>核心思想：通过连接产生候选项与其支持度，然后通过剪枝生成频繁项集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connect_string</span><span class="params">(x, ms)</span>:</span></span><br><span class="line">    x = list(map(<span class="keyword">lambda</span> i:sorted(i.split(ms)), x))</span><br><span class="line">    l = len(x[<span class="number">0</span>])</span><br><span class="line">    r = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i,len(x)):</span><br><span class="line">            <span class="keyword">if</span> x[i][:l<span class="number">-1</span>] == x[j][:l<span class="number">-1</span>] <span class="keyword">and</span> x[i][l<span class="number">-1</span>] != x[j][l<span class="number">-1</span>]:</span><br><span class="line">                r.append(x[i][:l<span class="number">-1</span>]+sorted([x[j][l<span class="number">-1</span>],x[i][l<span class="number">-1</span>]]))</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line"><span class="comment">#寻找关联规则的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_rule</span><span class="params">(d, support, confidence, ms = <span class="string">u'--'</span>)</span>:</span></span><br><span class="line">    result = pd.DataFrame(index=[<span class="string">'support'</span>, <span class="string">'confidence'</span>]) <span class="comment">#定义输出结果</span></span><br><span class="line">  </span><br><span class="line">    support_series = <span class="number">1.0</span>*d.sum()/len(d) <span class="comment">#支持度序列</span></span><br><span class="line">    column = list(support_series[support_series &gt; support].index) <span class="comment">#初步根据支持度筛选</span></span><br><span class="line">    k = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(column) &gt; <span class="number">1</span>:</span><br><span class="line">    	k = k+<span class="number">1</span></span><br><span class="line">    	print(<span class="string">u'\n正在进行第%s次搜索...'</span> %k)</span><br><span class="line">    	column = connect_string(column, ms)</span><br><span class="line">    	print(<span class="string">u'数目：%s...'</span> %len(column))</span><br><span class="line">    	sf = <span class="keyword">lambda</span> i: d[i].prod(axis=<span class="number">1</span>, numeric_only = <span class="literal">True</span>) <span class="comment">#新一批支持度的计算函数</span></span><br><span class="line">    	</span><br><span class="line">    	<span class="comment">#创建连接数据，这一步耗时、耗内存最严重。当数据集较大时，可以考虑并行运算优化。</span></span><br><span class="line">    	d_2 = pd.DataFrame(list(map(sf,column)), index = [ms.join(i) <span class="keyword">for</span> i <span class="keyword">in</span> column]).T</span><br><span class="line">    	</span><br><span class="line">    	support_series_2 = <span class="number">1.0</span>*d_2[[ms.join(i) <span class="keyword">for</span> i <span class="keyword">in</span> column]].sum()/len(d) <span class="comment">#计算连接后的支持度</span></span><br><span class="line">    	column = list(support_series_2[support_series_2 &gt; support].index) <span class="comment">#新一轮支持度筛选</span></span><br><span class="line">    	support_series = support_series.append(support_series_2)</span><br><span class="line">    	column2 = []</span><br><span class="line">    	</span><br><span class="line">    	<span class="keyword">for</span> i <span class="keyword">in</span> column: <span class="comment">#遍历可能的推理，如&#123;A,B,C&#125;究竟是A+B--&gt;C还是B+C--&gt;A还是C+A--&gt;B？</span></span><br><span class="line">    	    i = i.split(ms)</span><br><span class="line">    	    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(i)):</span><br><span class="line">    		    column2.append(i[:j]+i[j+<span class="number">1</span>:]+i[j:j+<span class="number">1</span>])</span><br><span class="line">    	</span><br><span class="line">    	cofidence_series = pd.Series(index=[ms.join(i) <span class="keyword">for</span> i <span class="keyword">in</span> column2]) <span class="comment">#定义置信度序列</span></span><br><span class="line">     </span><br><span class="line">    	<span class="keyword">for</span> i <span class="keyword">in</span> column2: <span class="comment">#计算置信度序列</span></span><br><span class="line">    	    cofidence_series[ms.join(i)] = support_series[ms.join(sorted(i))]/support_series[ms.join(i[:len(i)<span class="number">-1</span>])]</span><br><span class="line">    	</span><br><span class="line">    	<span class="keyword">for</span> i <span class="keyword">in</span> cofidence_series[cofidence_series &gt; confidence].index: <span class="comment">#置信度筛选</span></span><br><span class="line">    	    result[i] = <span class="number">0.0</span></span><br><span class="line">    	    result[i][<span class="string">'confidence'</span>] = cofidence_series[i]</span><br><span class="line">    	    result[i][<span class="string">'support'</span>] = support_series[ms.join(sorted(i.split(ms)))]</span><br><span class="line">  </span><br><span class="line">    result = result.T.sort_values([<span class="string">'confidence'</span>,<span class="string">'support'</span>], ascending = <span class="literal">False</span>) <span class="comment">#结果整理，输出</span></span><br><span class="line">    print(<span class="string">u'\n结果为：'</span>)</span><br><span class="line">    print(result)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><blockquote>
<p>数据挖掘六个步骤<br>每个步骤展开三个层次</p>
<p>例如：</p>
<p>第三个步骤  数据预处理<br>    第一个层次 ：数据缺省值 如何处理 数据的转换 处理方法，缺失值删除，属性删除，插值（均值插值 牛顿法 拉格朗日法）<br>    第二个层次：……</p>
</blockquote>
<h2 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a><a href="https://github1s.com/Olvi73/Python_DM" target="_blank" rel="noopener">实验代码</a></h2><h2 id="chapter-6"><a href="#chapter-6" class="headerlink" title="chapter 6"></a>chapter 6</h2><h3 id="GM11-py"><a href="#GM11-py" class="headerlink" title="GM11.py"></a>GM11.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GM11</span><span class="params">(x0)</span>:</span> <span class="comment">#自定义灰色预测函数</span></span><br><span class="line">  <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">  x1 = x0.cumsum() <span class="comment">#1-AGO序列</span></span><br><span class="line">  z1 = (x1[:len(x1)<span class="number">-1</span>] + x1[<span class="number">1</span>:])/<span class="number">2.0</span> <span class="comment">#紧邻均值（MEAN）生成序列</span></span><br><span class="line">  z1 = z1.reshape((len(z1),<span class="number">1</span>))</span><br><span class="line">  B = np.append(-z1, np.ones_like(z1), axis = <span class="number">1</span>)</span><br><span class="line">  Yn = x0[<span class="number">1</span>:].reshape((len(x0)<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">  [[a],[b]] = np.dot(np.dot(np.linalg.inv(np.dot(B.T, B)), B.T), Yn) <span class="comment">#计算参数</span></span><br><span class="line">  f = <span class="keyword">lambda</span> k: (x0[<span class="number">0</span>]-b/a)*np.exp(-a*(k<span class="number">-1</span>))-(x0[<span class="number">0</span>]-b/a)*np.exp(-a*(k<span class="number">-2</span>)) <span class="comment">#还原值</span></span><br><span class="line">  delta = np.abs(x0 - np.array([f(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(x0)+<span class="number">1</span>)]))</span><br><span class="line">  C = delta.std()/x0.std()</span><br><span class="line">  P = <span class="number">1.0</span>*(np.abs(delta - delta.mean()) &lt; <span class="number">0.6745</span>*x0.std()).sum()/len(x0)</span><br><span class="line">  <span class="keyword">return</span> f, a, b, x0[<span class="number">0</span>], C, P <span class="comment">#返回灰色预测函数、a、b、首项、方差比、小残差概率</span></span><br></pre></td></tr></table></figure>

<h3 id="01-lasso-py"><a href="#01-lasso-py" class="headerlink" title="01-lasso.py"></a>01-lasso.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"></span><br><span class="line">inputfile = <span class="string">'../data/data.csv'</span>  <span class="comment"># 输入的数据文件</span></span><br><span class="line">data = pd.read_csv(inputfile)  <span class="comment"># 读取数据</span></span><br><span class="line">lasso = Lasso(<span class="number">1000</span>)  <span class="comment"># 调用Lasso()函数，设置λ的值为1000</span></span><br><span class="line">lasso.fit(data.iloc[:,<span class="number">0</span>:<span class="number">14</span>],data[<span class="string">'y'</span>])</span><br><span class="line">print(<span class="string">'相关系数为：'</span>,np.round(lasso.coef_,<span class="number">5</span>))  <span class="comment"># 输出结果，保留五位小数</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'相关系数非零个数为：'</span>,np.sum(lasso.coef_ != <span class="number">0</span>))  <span class="comment"># 计算相关系数非零的个数</span></span><br><span class="line"></span><br><span class="line">mask = lasso.coef_ != <span class="number">0</span>  <span class="comment"># 返回一个相关系数是否为零的布尔数组</span></span><br><span class="line">print(<span class="string">'相关系数是否为零：'</span>,mask)</span><br><span class="line"></span><br><span class="line">outputfile =<span class="string">'../tmp/new_reg_data.csv'</span>  <span class="comment"># 输出的数据文件</span></span><br><span class="line">new_reg_data = data.iloc[:, mask]  <span class="comment"># 返回相关系数非零的数据</span></span><br><span class="line">new_reg_data.to_csv(outputfile)  <span class="comment"># 存储数据</span></span><br><span class="line">print(<span class="string">'输出数据的维度为：'</span>,new_reg_data.shape)  <span class="comment"># 查看输出数据的维度</span></span><br></pre></td></tr></table></figure>

<h3 id="02-gm-predict-py"><a href="#02-gm-predict-py" class="headerlink" title="02-gm_predict.py"></a>02-gm_predict.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'../code'</span>)  <span class="comment"># 设置路径</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> GM11 <span class="keyword">import</span> GM11  <span class="comment"># 引入自编的灰色预测函数</span></span><br><span class="line"></span><br><span class="line">inputfile1 = <span class="string">'../tmp/new_reg_data.csv'</span>  <span class="comment"># 输入的数据文件</span></span><br><span class="line">inputfile2 = <span class="string">'../data/data.csv'</span>  <span class="comment"># 输入的数据文件</span></span><br><span class="line">new_reg_data = pd.read_csv(inputfile1)  <span class="comment"># 读取经过特征选择后的数据</span></span><br><span class="line">data = pd.read_csv(inputfile2)  <span class="comment"># 读取总的数据</span></span><br><span class="line">new_reg_data.index = range(<span class="number">1994</span>, <span class="number">2014</span>)</span><br><span class="line">new_reg_data.loc[<span class="number">2014</span>] = <span class="literal">None</span></span><br><span class="line">new_reg_data.loc[<span class="number">2015</span>] = <span class="literal">None</span></span><br><span class="line"><span class="comment"># l = ['x1', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x13']</span></span><br><span class="line">l = [<span class="string">'x1'</span>, <span class="string">'x4'</span>, <span class="string">'x5'</span>, <span class="string">'x6'</span>, <span class="string">'x7'</span>, <span class="string">'x8'</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> l:</span><br><span class="line">  f = GM11(new_reg_data.loc[range(<span class="number">1994</span>, <span class="number">2014</span>),i].values)[<span class="number">0</span>]</span><br><span class="line">  new_reg_data.loc[<span class="number">2014</span>,i] = f(len(new_reg_data)<span class="number">-1</span>)  <span class="comment"># 2014年预测结果</span></span><br><span class="line">  new_reg_data.loc[<span class="number">2015</span>,i] = f(len(new_reg_data))  <span class="comment"># 2015年预测结果</span></span><br><span class="line">  new_reg_data[i] = new_reg_data[i].round(<span class="number">2</span>)  <span class="comment"># 保留两位小数</span></span><br><span class="line">outputfile = <span class="string">'../tmp/new_reg_data_GM11.xls'</span>  <span class="comment"># 灰色预测后保存的路径</span></span><br><span class="line">y = list(data[<span class="string">'y'</span>].values)  <span class="comment"># 提取财政收入列，合并至新数据框中</span></span><br><span class="line">y.extend([np.nan,np.nan])</span><br><span class="line">new_reg_data[<span class="string">'y'</span>] = y</span><br><span class="line">new_reg_data.to_excel(outputfile)  <span class="comment"># 结果输出</span></span><br><span class="line">print(<span class="string">'预测结果为：\n'</span>,new_reg_data.loc[<span class="number">2014</span>:<span class="number">2015</span>,:])  <span class="comment"># 预测结果展示</span></span><br></pre></td></tr></table></figure>

<h3 id="03-svr-predict-py"><a href="#03-svr-predict-py" class="headerlink" title="03-svr_predict.py"></a>03-svr_predict.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVR</span><br><span class="line"></span><br><span class="line">inputfile = <span class="string">'../tmp/new_reg_data_GM11.xls'</span>  <span class="comment"># 灰色预测后保存的路径</span></span><br><span class="line">data = pd.read_excel(inputfile)  <span class="comment"># 读取数据</span></span><br><span class="line">np.array(data)</span><br><span class="line"><span class="comment"># feature = ['x1', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x13']  # 属性所在列</span></span><br><span class="line">feature = [<span class="string">'x1'</span>, <span class="string">'x4'</span>, <span class="string">'x5'</span>, <span class="string">'x6'</span>, <span class="string">'x7'</span>, <span class="string">'x8'</span>]  <span class="comment"># 属性所在列</span></span><br><span class="line">data_train = data.loc[range(<span class="number">0</span>,<span class="number">20</span>)].copy()  <span class="comment"># 取2014年前的数据建模</span></span><br><span class="line">data_mean = data_train.mean()</span><br><span class="line">data_std = data_train.std()</span><br><span class="line">data_train = (data_train - data_mean)/data_std  <span class="comment"># 数据标准化</span></span><br><span class="line">x_train = data_train[feature].values  <span class="comment"># 属性数据</span></span><br><span class="line">y_train = data_train[<span class="string">'y'</span>].values  <span class="comment"># 标签数据</span></span><br><span class="line"></span><br><span class="line">linearsvr = LinearSVR()  <span class="comment"># 调用LinearSVR()函数</span></span><br><span class="line">linearsvr.fit(x_train,y_train)</span><br><span class="line">x = ((data[feature] - data_mean[feature])/data_std[feature]).values  <span class="comment"># 预测，并还原结果。</span></span><br><span class="line">data[<span class="string">u'y_pred'</span>] = linearsvr.predict(x) * data_std[<span class="string">'y'</span>] + data_mean[<span class="string">'y'</span>]</span><br><span class="line">outputfile = <span class="string">'../tmp/new_reg_data_GM11_revenue.xls'</span>  <span class="comment"># SVR预测后保存的结果</span></span><br><span class="line">data.to_excel(outputfile)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'真实值与预测值分别为：\n'</span>,data[[<span class="string">'y'</span>,<span class="string">'y_pred'</span>]])</span><br><span class="line"></span><br><span class="line">fig = data[[<span class="string">'y'</span>,<span class="string">'y_pred'</span>]].plot(subplots = <span class="literal">True</span>, style=[<span class="string">'b-o'</span>,<span class="string">'r-*'</span>])  <span class="comment"># 画出预测结果图</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="chapter-7"><a href="#chapter-7" class="headerlink" title="chapter 7"></a>chapter 7</h2><h3 id="01-data-explore-py"><a href="#01-data-explore-py" class="headerlink" title="01-data_explore.py"></a>01-data_explore.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据进行基本的探索</span></span><br><span class="line"><span class="comment"># 返回缺失值个数以及最大最小值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">datafile= <span class="string">'../data/air_data.csv'</span>  <span class="comment"># 航空原始数据,第一行为属性标签</span></span><br><span class="line">resultfile = <span class="string">'../tmp/explore.csv'</span>  <span class="comment"># 数据探索结果表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取原始数据，指定UTF-8编码（需要用文本编辑器将数据装换为UTF-8编码）</span></span><br><span class="line">data = pd.read_csv(datafile, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 包括对数据的基本描述，percentiles参数是指定计算多少的分位数表（如1/4分位数、中位数等）</span></span><br><span class="line">explore = data.describe(percentiles = [], include = <span class="string">'all'</span>).T  <span class="comment"># T是转置，转置后更方便查阅</span></span><br><span class="line">explore[<span class="string">'null'</span>] = len(data)-explore[<span class="string">'count'</span>]  <span class="comment"># describe()函数自动计算非空值数，需要手动计算空值数</span></span><br><span class="line"></span><br><span class="line">explore = explore[[<span class="string">'null'</span>, <span class="string">'max'</span>, <span class="string">'min'</span>]]</span><br><span class="line">explore.columns = [<span class="string">u'空值数'</span>, <span class="string">u'最大值'</span>, <span class="string">u'最小值'</span>]  <span class="comment"># 表头重命名</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">这里只选取部分探索结果。</span></span><br><span class="line"><span class="string">describe()函数自动计算的字段有count（非空值数）、unique（唯一值数）、top（频数最高者）、</span></span><br><span class="line"><span class="string">freq（最高频数）、mean（平均值）、std（方差）、min（最小值）、50%（中位数）、max（最大值）</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">explore.to_csv(resultfile)  <span class="comment"># 导出结果</span></span><br></pre></td></tr></table></figure>

<h3 id="02-data-distribution-py"><a href="#02-data-distribution-py" class="headerlink" title="02-data_distribution.py"></a>02-data_distribution.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据的分布分析</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">datafile= <span class="string">'../data/air_data.csv'</span>  <span class="comment"># 航空原始数据,第一行为属性标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取原始数据，指定UTF-8编码（需要用文本编辑器将数据装换为UTF-8编码）</span></span><br><span class="line">data = pd.read_csv(datafile, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 客户信息类别</span></span><br><span class="line"><span class="comment"># 提取会员入会年份</span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">ffp = data[<span class="string">'FFP_DATE'</span>].apply(<span class="keyword">lambda</span> x:datetime.strptime(x,<span class="string">'%Y/%m/%d'</span>))</span><br><span class="line">ffp_year = ffp.map(<span class="keyword">lambda</span> x : x.year)</span><br><span class="line"><span class="comment"># 绘制各年份会员入会人数直方图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">8</span> ,<span class="number">5</span>))  <span class="comment"># 设置画布大小</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = <span class="string">'SimHei'</span>  <span class="comment"># 设置中文显示</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">plt.hist(ffp_year, bins=<span class="string">'auto'</span>, color=<span class="string">'#0504aa'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'年份'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'入会人数'</span>)</span><br><span class="line">plt.title(<span class="string">'各年份会员入会人数'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取会员不同性别人数</span></span><br><span class="line">male = pd.value_counts(data[<span class="string">'GENDER'</span>])[<span class="string">'男'</span>]</span><br><span class="line">female = pd.value_counts(data[<span class="string">'GENDER'</span>])[<span class="string">'女'</span>]</span><br><span class="line"><span class="comment"># 绘制会员性别比例饼图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">7</span> ,<span class="number">4</span>))  <span class="comment"># 设置画布大小</span></span><br><span class="line">plt.pie([ male, female], labels=[<span class="string">'男'</span>,<span class="string">'女'</span>], colors=[<span class="string">'lightskyblue'</span>, <span class="string">'lightcoral'</span>],</span><br><span class="line">       autopct=<span class="string">'%1.1f%%'</span>)</span><br><span class="line">plt.title(<span class="string">'会员性别比例'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取不同级别会员的人数</span></span><br><span class="line">lv_four = pd.value_counts(data[<span class="string">'FFP_TIER'</span>])[<span class="number">4</span>]</span><br><span class="line">lv_five = pd.value_counts(data[<span class="string">'FFP_TIER'</span>])[<span class="number">5</span>]</span><br><span class="line">lv_six = pd.value_counts(data[<span class="string">'FFP_TIER'</span>])[<span class="number">6</span>]</span><br><span class="line"><span class="comment"># 绘制会员各级别人数条形图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">8</span> ,<span class="number">5</span>))  <span class="comment"># 设置画布大小</span></span><br><span class="line">plt.bar(x=range(<span class="number">3</span>), height=[lv_four,lv_five,lv_six], width=<span class="number">0.4</span>, alpha=<span class="number">0.8</span>, color=<span class="string">'skyblue'</span>)</span><br><span class="line">plt.xticks([index <span class="keyword">for</span> index <span class="keyword">in</span> range(<span class="number">3</span>)], [<span class="string">'4'</span>,<span class="string">'5'</span>,<span class="string">'6'</span>])</span><br><span class="line">plt.xlabel(<span class="string">'会员等级'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'会员人数'</span>)</span><br><span class="line">plt.title(<span class="string">'会员各级别人数'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取会员年龄</span></span><br><span class="line">age = data[<span class="string">'AGE'</span>].dropna()</span><br><span class="line">age = age.astype(<span class="string">'int64'</span>)</span><br><span class="line"><span class="comment"># 绘制会员年龄分布箱型图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">5</span> ,<span class="number">10</span>))</span><br><span class="line">plt.boxplot(age, </span><br><span class="line">            patch_artist=<span class="literal">True</span>,</span><br><span class="line">            labels = [<span class="string">'会员年龄'</span>],  <span class="comment"># 设置x轴标题</span></span><br><span class="line">            boxprops = &#123;<span class="string">'facecolor'</span>:<span class="string">'lightblue'</span>&#125;)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">plt.title(<span class="string">'会员年龄分布箱线图'</span>)</span><br><span class="line"><span class="comment"># 显示y坐标轴的底线</span></span><br><span class="line">plt.grid(axis=<span class="string">'y'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 乘机信息类别</span></span><br><span class="line">lte = data[<span class="string">'LAST_TO_END'</span>]</span><br><span class="line">fc = data[<span class="string">'FLIGHT_COUNT'</span>]</span><br><span class="line">sks = data[<span class="string">'SEG_KM_SUM'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制最后乘机至结束时长箱线图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">5</span> ,<span class="number">8</span>))</span><br><span class="line">plt.boxplot(lte, </span><br><span class="line">            patch_artist=<span class="literal">True</span>,</span><br><span class="line">            labels = [<span class="string">'时长'</span>],  <span class="comment"># 设置x轴标题</span></span><br><span class="line">            boxprops = &#123;<span class="string">'facecolor'</span>:<span class="string">'lightblue'</span>&#125;)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">plt.title(<span class="string">'会员最后乘机至结束时长分布箱线图'</span>)</span><br><span class="line"><span class="comment"># 显示y坐标轴的底线</span></span><br><span class="line">plt.grid(axis=<span class="string">'y'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制客户飞行次数箱线图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">5</span> ,<span class="number">8</span>))</span><br><span class="line">plt.boxplot(fc, </span><br><span class="line">            patch_artist=<span class="literal">True</span>,</span><br><span class="line">            labels = [<span class="string">'飞行次数'</span>],  <span class="comment"># 设置x轴标题</span></span><br><span class="line">            boxprops = &#123;<span class="string">'facecolor'</span>:<span class="string">'lightblue'</span>&#125;)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">plt.title(<span class="string">'会员飞行次数分布箱线图'</span>)</span><br><span class="line"><span class="comment"># 显示y坐标轴的底线</span></span><br><span class="line">plt.grid(axis=<span class="string">'y'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制客户总飞行公里数箱线图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">5</span> ,<span class="number">10</span>))</span><br><span class="line">plt.boxplot(sks, </span><br><span class="line">            patch_artist=<span class="literal">True</span>,</span><br><span class="line">            labels = [<span class="string">'总飞行公里数'</span>],  <span class="comment"># 设置x轴标题</span></span><br><span class="line">            boxprops = &#123;<span class="string">'facecolor'</span>:<span class="string">'lightblue'</span>&#125;)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">plt.title(<span class="string">'客户总飞行公里数箱线图'</span>)</span><br><span class="line"><span class="comment"># 显示y坐标轴的底线</span></span><br><span class="line">plt.grid(axis=<span class="string">'y'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 积分信息类别</span></span><br><span class="line"><span class="comment"># 提取会员积分兑换次数</span></span><br><span class="line">ec = data[<span class="string">'EXCHANGE_COUNT'</span>]</span><br><span class="line"><span class="comment"># 绘制会员兑换积分次数直方图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">8</span> ,<span class="number">5</span>))  <span class="comment"># 设置画布大小</span></span><br><span class="line">plt.hist(ec, bins=<span class="number">5</span>, color=<span class="string">'#0504aa'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'兑换次数'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'会员人数'</span>)</span><br><span class="line">plt.title(<span class="string">'会员兑换积分次数分布直方图'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取会员总累计积分</span></span><br><span class="line">ps = data[<span class="string">'Points_Sum'</span>]</span><br><span class="line"><span class="comment"># 绘制会员总累计积分箱线图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">5</span> ,<span class="number">8</span>))</span><br><span class="line">plt.boxplot(ps, </span><br><span class="line">            patch_artist=<span class="literal">True</span>,</span><br><span class="line">            labels = [<span class="string">'总累计积分'</span>],  <span class="comment"># 设置x轴标题</span></span><br><span class="line">            boxprops = &#123;<span class="string">'facecolor'</span>:<span class="string">'lightblue'</span>&#125;)  <span class="comment"># 设置填充颜色</span></span><br><span class="line">plt.title(<span class="string">'客户总累计积分箱线图'</span>)</span><br><span class="line"><span class="comment"># 显示y坐标轴的底线</span></span><br><span class="line">plt.grid(axis=<span class="string">'y'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取属性并合并为新数据集</span></span><br><span class="line">data_corr = data[[<span class="string">'FFP_TIER'</span>,<span class="string">'FLIGHT_COUNT'</span>,<span class="string">'LAST_TO_END'</span>,</span><br><span class="line">                  <span class="string">'SEG_KM_SUM'</span>,<span class="string">'EXCHANGE_COUNT'</span>,<span class="string">'Points_Sum'</span>]]</span><br><span class="line">age1 = data[<span class="string">'AGE'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">data_corr[<span class="string">'AGE'</span>] = age1.astype(<span class="string">'int64'</span>)</span><br><span class="line">data_corr[<span class="string">'ffp_year'</span>] = ffp_year</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算相关性矩阵</span></span><br><span class="line">dt_corr = data_corr.corr(method = <span class="string">'pearson'</span>)</span><br><span class="line">print(<span class="string">'相关性矩阵为：\n'</span>,dt_corr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制热力图</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">plt.subplots(figsize=(<span class="number">10</span>, <span class="number">10</span>)) <span class="comment"># 设置画面大小 </span></span><br><span class="line">sns.heatmap(dt_corr, annot=<span class="literal">True</span>, vmax=<span class="number">1</span>, square=<span class="literal">True</span>, cmap=<span class="string">'Blues'</span>) </span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br></pre></td></tr></table></figure>

<h3 id="03-data-clean-py"><a href="#03-data-clean-py" class="headerlink" title="03-data_clean.py"></a>03-data_clean.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理缺失值与异常值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">datafile = <span class="string">'../data/air_data.csv'</span>  <span class="comment"># 航空原始数据路径</span></span><br><span class="line">cleanedfile = <span class="string">'../tmp/data_cleaned.csv'</span>  <span class="comment"># 数据清洗后保存的文件路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">airline_data = pd.read_csv(datafile,encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">print(<span class="string">'原始数据的形状为：'</span>,airline_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除票价为空的记录</span></span><br><span class="line">airline_notnull = airline_data.loc[airline_data[<span class="string">'SUM_YR_1'</span>].notnull() &amp; </span><br><span class="line">                                   airline_data[<span class="string">'SUM_YR_2'</span>].notnull(),:]</span><br><span class="line">print(<span class="string">'删除缺失记录后数据的形状为：'</span>,airline_notnull.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只保留票价非零的，或者平均折扣率不为0且总飞行公里数大于0的记录。</span></span><br><span class="line">index1 = airline_notnull[<span class="string">'SUM_YR_1'</span>] != <span class="number">0</span></span><br><span class="line">index2 = airline_notnull[<span class="string">'SUM_YR_2'</span>] != <span class="number">0</span></span><br><span class="line">index3 = (airline_notnull[<span class="string">'SEG_KM_SUM'</span>]&gt; <span class="number">0</span>) &amp; (airline_notnull[<span class="string">'avg_discount'</span>] != <span class="number">0</span>)</span><br><span class="line">index4 = airline_notnull[<span class="string">'AGE'</span>] &gt; <span class="number">100</span>  <span class="comment"># 去除年龄大于100的记录</span></span><br><span class="line">airline = airline_notnull[(index1 | index2) &amp; index3 &amp; ~index4]</span><br><span class="line">print(<span class="string">'数据清洗后数据的形状为：'</span>,airline.shape)</span><br><span class="line"></span><br><span class="line">airline.to_csv(cleanedfile)  <span class="comment"># 保存清洗后的数据</span></span><br></pre></td></tr></table></figure>

<h3 id="04-zscore-data-py"><a href="#04-zscore-data-py" class="headerlink" title="04-zscore_data.py"></a>04-zscore_data.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 属性选择、构造与数据标准化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据清洗后的数据</span></span><br><span class="line">cleanedfile = <span class="string">'../tmp/data_cleaned.csv'</span>  <span class="comment"># 数据清洗后保存的文件路径</span></span><br><span class="line">airline = pd.read_csv(cleanedfile, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 选取需求属性</span></span><br><span class="line">airline_selection = airline[[<span class="string">'FFP_DATE'</span>,<span class="string">'LOAD_TIME'</span>,<span class="string">'LAST_TO_END'</span>,</span><br><span class="line">                                     <span class="string">'FLIGHT_COUNT'</span>,<span class="string">'SEG_KM_SUM'</span>,<span class="string">'avg_discount'</span>]]</span><br><span class="line">print(<span class="string">'筛选的属性前5行为：\n'</span>,airline_selection.head())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造属性L</span></span><br><span class="line">L = pd.to_datetime(airline_selection[<span class="string">'LOAD_TIME'</span>]) - pd.to_datetime(airline_selection[<span class="string">'FFP_DATE'</span>])</span><br><span class="line">L = L.astype(<span class="string">'str'</span>).str.split().str[<span class="number">0</span>]</span><br><span class="line">L = L.astype(<span class="string">'int'</span>)/<span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并属性</span></span><br><span class="line">airline_features = pd.concat([L,airline_selection.iloc[:,<span class="number">2</span>:]],axis = <span class="number">1</span>)</span><br><span class="line">airline_features.columns = [<span class="string">'L'</span>,<span class="string">'R'</span>,<span class="string">'F'</span>,<span class="string">'M'</span>,<span class="string">'C'</span>]</span><br><span class="line">print(<span class="string">'构建的LRFMC属性前5行为：\n'</span>,airline_features.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">data = StandardScaler().fit_transform(airline_features)</span><br><span class="line">np.savez(<span class="string">'../tmp/airline_scale.npz'</span>,data)</span><br><span class="line">print(<span class="string">'标准化后LRFMC五个属性为：\n'</span>,data[:<span class="number">5</span>,:])</span><br></pre></td></tr></table></figure>

<h3 id="05-KMeans-cluster-py"><a href="#05-KMeans-cluster-py" class="headerlink" title="05-KMeans_cluster.py"></a>05-KMeans_cluster.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># K-means聚类</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans  <span class="comment"># 导入kmeans算法</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取标准化后的数据</span></span><br><span class="line">airline_scale = np.load(<span class="string">'../tmp/airline_scale.npz'</span>)[<span class="string">'arr_0'</span>]</span><br><span class="line">k = <span class="number">5</span>  <span class="comment"># 确定聚类中心数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型，随机种子设为123</span></span><br><span class="line">kmeans_model = KMeans(n_clusters = k,n_jobs=<span class="number">4</span>,random_state=<span class="number">123</span>)</span><br><span class="line">fit_kmeans = kmeans_model.fit(airline_scale)  <span class="comment"># 模型训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看聚类结果</span></span><br><span class="line">kmeans_cc = kmeans_model.cluster_centers_  <span class="comment"># 聚类中心</span></span><br><span class="line">print(<span class="string">'各类聚类中心为：\n'</span>,kmeans_cc)</span><br><span class="line">kmeans_labels = kmeans_model.labels_  <span class="comment"># 样本的类别标签</span></span><br><span class="line">print(<span class="string">'各样本的类别标签为：\n'</span>,kmeans_labels)</span><br><span class="line">r1 = pd.Series(kmeans_model.labels_).value_counts()  <span class="comment"># 统计不同类别样本的数目</span></span><br><span class="line">print(<span class="string">'最终每个类别的数目为：\n'</span>,r1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="comment"># 客户分群雷达图</span></span><br><span class="line">cluster_center = pd.DataFrame(kmeans_model.cluster_centers_,\</span><br><span class="line">             columns = [<span class="string">'ZL'</span>,<span class="string">'ZR'</span>,<span class="string">'ZF'</span>,<span class="string">'ZM'</span>,<span class="string">'ZC'</span>])   <span class="comment"># 将聚类中心放在数据框中</span></span><br><span class="line">cluster_center.index = pd.DataFrame(kmeans_model.labels_ ).\</span><br><span class="line">                  drop_duplicates().iloc[:,<span class="number">0</span>]  <span class="comment"># 将样本类别作为数据框索引</span></span><br><span class="line">print(cluster_center)</span><br><span class="line">labels = [<span class="string">'ZL'</span>,<span class="string">'ZR'</span>,<span class="string">'ZF'</span>,<span class="string">'ZM'</span>,<span class="string">'ZC'</span>]</span><br><span class="line">legen = [<span class="string">'客户群'</span> + str(i + <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> cluster_center.index]  <span class="comment"># 客户群命名，作为雷达图的图例</span></span><br><span class="line">lstype = [<span class="string">'-'</span>,<span class="string">'--'</span>,(<span class="number">0</span>, (<span class="number">3</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">5</span>)),<span class="string">':'</span>,<span class="string">'-.'</span>]</span><br><span class="line">kinds = list(cluster_center.iloc[:, <span class="number">0</span>])</span><br><span class="line"><span class="comment"># 由于雷达图要保证数据闭合，因此再添加L列，并转换为 np.ndarray</span></span><br><span class="line">cluster_center = pd.concat([cluster_center, cluster_center[[<span class="string">'ZL'</span>]]], axis=<span class="number">1</span>)</span><br><span class="line">centers = np.array(cluster_center.iloc[:, <span class="number">0</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割圆周长，并让其闭合</span></span><br><span class="line">n = len(labels)</span><br><span class="line">angle = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, n, endpoint=<span class="literal">False</span>)</span><br><span class="line">angle = np.concatenate((angle, [angle[<span class="number">0</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, polar=<span class="literal">True</span>)  <span class="comment"># 以极坐标的形式绘制图形</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号 </span></span><br><span class="line"><span class="comment"># 画线</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(kinds)):</span><br><span class="line">    ax.plot(angle, centers[i], linestyle=lstype[i], linewidth=<span class="number">2</span>, label=kinds[i])</span><br><span class="line"><span class="comment"># 添加属性标签</span></span><br><span class="line">ax.set_thetagrids(angle * <span class="number">180</span> / np.pi, labels)</span><br><span class="line">plt.title(<span class="string">'客户特征分析雷达图'</span>)</span><br><span class="line">plt.legend(legen)</span><br><span class="line">plt.show()</span><br><span class="line">plt.close</span><br></pre></td></tr></table></figure>


    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Python/" rel="tag"># Python</a>
            
              <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
            
              <a href="/tags/数据挖掘/" rel="tag"># 数据挖掘</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/p/c34b.html" rel="next" title="编译原理考试总结">
                  <i class="fa fa-chevron-left"></i> 编译原理考试总结
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      
      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数据挖掘"><span class="nav-text">数据挖掘</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据挖掘基本任务"><span class="nav-text">数据挖掘基本任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据挖掘建模过程"><span class="nav-text">数据挖掘建模过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-目标定义"><span class="nav-text">1.目标定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-数据采集"><span class="nav-text">2.数据采集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-数据整理"><span class="nav-text">3.数据整理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-构建模型"><span class="nav-text">4.构建模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-模型评价"><span class="nav-text">5.模型评价</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-模型发布"><span class="nav-text">6.模型发布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第三章-数据探索-P39"><span class="nav-text">第三章 数据探索 P39</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-数据质量分析"><span class="nav-text">1.数据质量分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#主要任务"><span class="nav-text">主要任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缺失值分析"><span class="nav-text">缺失值分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#产生的原因"><span class="nav-text">产生的原因</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#缺失值的影响"><span class="nav-text">缺失值的影响</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#缺失值的分析"><span class="nav-text">缺失值的分析</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#异常值分析"><span class="nav-text">异常值分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-简单统计量分析"><span class="nav-text">1. 简单统计量分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3σ准则"><span class="nav-text">2. 3σ准则</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-箱型图分析"><span class="nav-text">3. 箱型图分析</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#一致性分析"><span class="nav-text">一致性分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-数据特征分析"><span class="nav-text">2. 数据特征分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-分布分析"><span class="nav-text">1. 分布分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-定量数据的分布分析"><span class="nav-text">1. 定量数据的分布分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-定性数据分析"><span class="nav-text">2. 定性数据分析</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-对比分析"><span class="nav-text">2. 对比分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-统计量分析"><span class="nav-text">3. 统计量分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-集中趋势程度"><span class="nav-text">1. 集中趋势程度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-离中趋势度量"><span class="nav-text">2. 离中趋势度量</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-周期性分析"><span class="nav-text">4. 周期性分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-贡献度分析"><span class="nav-text">5. 贡献度分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-相关性分析"><span class="nav-text">6. 相关性分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-直接绘制散点图"><span class="nav-text">1. 直接绘制散点图</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-绘制散点图矩阵"><span class="nav-text">2. 绘制散点图矩阵</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-计算相关系数"><span class="nav-text">3. 计算相关系数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Python主要数据探索函数"><span class="nav-text">Python主要数据探索函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-基本统计特征函数"><span class="nav-text">1. 基本统计特征函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-拓展统计特征函数"><span class="nav-text">2. 拓展统计特征函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-统计绘图函数"><span class="nav-text">3. 统计绘图函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-代码实例"><span class="nav-text">4. 代码实例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第四章-数据预处理-P75"><span class="nav-text">第四章 数据预处理 P75</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-数据清洗"><span class="nav-text">1. 数据清洗</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-缺失值处理"><span class="nav-text">1. 缺失值处理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-拉格朗日插值法"><span class="nav-text">1. 拉格朗日插值法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-牛顿插值法"><span class="nav-text">2. 牛顿插值法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-异常值处理"><span class="nav-text">2. 异常值处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-数据集成"><span class="nav-text">2. 数据集成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-实体识别"><span class="nav-text">1. 实体识别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-冗余属性识别"><span class="nav-text">2. 冗余属性识别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-数据变换"><span class="nav-text">3. 数据变换</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-数据规约"><span class="nav-text">3. 数据规约</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-属性规约"><span class="nav-text">1. 属性规约</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#主成分分析计算步骤"><span class="nav-text">主成分分析计算步骤</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-数值规约"><span class="nav-text">2. 数值规约</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Python主要数据预处理函数"><span class="nav-text">4. Python主要数据预处理函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#代码实例"><span class="nav-text">代码实例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第五章-挖掘建模-P102"><span class="nav-text">第五章 挖掘建模 P102</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-分类与预测"><span class="nav-text">1. 分类与预测</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-实现过程"><span class="nav-text">1. 实现过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-常用的分类与预测算法"><span class="nav-text">2. 常用的分类与预测算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-回归分析"><span class="nav-text">3. 回归分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-决策树"><span class="nav-text">4. 决策树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-人工神经网络"><span class="nav-text">5. 人工神经网络</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-聚类分析"><span class="nav-text">2. 聚类分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#K-Means聚类分析"><span class="nav-text">K-Means聚类分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-算法过程"><span class="nav-text">1. 算法过程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-代码实例"><span class="nav-text">2. 代码实例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-关联规则"><span class="nav-text">3. 关联规则</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Apriori算法"><span class="nav-text">Apriori算法</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#其他"><span class="nav-text">其他</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#实验代码"><span class="nav-text">实验代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#chapter-6"><span class="nav-text">chapter 6</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GM11-py"><span class="nav-text">GM11.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#01-lasso-py"><span class="nav-text">01-lasso.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#02-gm-predict-py"><span class="nav-text">02-gm_predict.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#03-svr-predict-py"><span class="nav-text">03-svr_predict.py</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#chapter-7"><span class="nav-text">chapter 7</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#01-data-explore-py"><span class="nav-text">01-data_explore.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#02-data-distribution-py"><span class="nav-text">02-data_distribution.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#03-data-clean-py"><span class="nav-text">03-data_clean.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#04-zscore-data-py"><span class="nav-text">04-zscore_data.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#05-KMeans-cluster-py"><span class="nav-text">05-KMeans_cluster.py</span></a></li></ol></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="Olvi73">
  <p class="site-author-name" itemprop="name">Olvi73</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">109</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">76</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://github.com/Olvi73" title="GitHub" rel="noopener" target="_blank"><i class="fa fa-fw fa-github-alt"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="mailto:oliver73@foxmail.com" title="E-Mail" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
    
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
      



      
    
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>
     
     

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Olvi73</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">34k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">30 分钟</span>
</div>

<!--添加运行时间-->
<span id="sitetime"></span>
<script language=javascript>
  function siteTime(){
    window.setTimeout("siteTime()", 1000);
    var seconds = 1000;
    var minutes = seconds * 60;
    var hours = minutes * 60;
    var days = hours * 24;
    var years = days * 365;
    var today = new Date();
    var todayYear = today.getFullYear();
    var todayMonth = today.getMonth();
    var todayDate = today.getDate();
    var todayHour = today.getHours();
    var todayMinute = today.getMinutes();
    var todaySecond = today.getSeconds();
    /* 
      Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数
     */
    var t1 = Date.UTC(2019,9,26,13,24,30); //北京时间2019-9-26 00:00:00
    var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
    var diff = t2-t1;
    var diffYears = Math.floor(diff/years);
    var diffDays = Math.floor((diff/days)-diffYears*365);
    var diffDays2 = Math.floor((diff/days));
    var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
    var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
    var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
    document.getElementById("sitetime").innerHTML=" 本站已运行 "+/*diffYears+" 年 "+*/diffDays2+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
  }
  siteTime();
</script>
<br>
<!--// 添加运行时间-->

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  


    
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/muse.js?v=7.4.0"></script>

<script src="/js/next-boot.js?v=7.4.0"></script>



  








  <script src="/js/local-search.js?v=7.4.0"></script>














  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: '2BoF0h2i6i4uIS7QVXXvQjuf-gzGzoHsz',
    appKey: 'HpjIdHik7yGMhGm9XmoL8OrS',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>



               <!-- 音频播放 外链失效太快，暂时放弃-->
 <!--
<link rel="stylesheet" href="/dist/APlayer.min.css">
<div id="aplayer" style="position:absolute;left;0;bottom:0;"></div>
<script type="text/javascript" src="/dist/APlayer.min.js"></script>
<script type="text/javascript" src="/dist/music.js"></script> 
-->

  <!-- 页面点击小红心，在末尾添加，避免找不到 -->
  
  
      <script type="text/javascript" src="/js/clicklove.js"></script>
  
</body>
</html>
